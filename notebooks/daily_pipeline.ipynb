{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily arXiv Embeddings Pipeline\n",
    "\n",
    "This notebook fetches daily arXiv preprints via RSS, generates embeddings using sentence-transformers, and stores them in Hopsworks Feature Store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q feedparser sentence-transformers \"hopsworks[python]==4.2.*\"\n",
    "\n",
    "# Restart runtime after install (required for numpy compatibility)\n",
    "#import os\n",
    "#os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import urllib.request\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "from datetime import datetime\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import hopsworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading categories from: https://raw.githubusercontent.com/Edwinexd/arxiv-rag-agent/refs/heads/master/data/arxiv_v2.csv\n",
      "Loading categories from: data/arxiv_v2.csv\n",
      "Found 155 categories\n",
      "\n",
      "Categories to fetch: 155\n",
      "Delay between requests: 5s\n",
      "Estimated fetch time: ~12 min 55s\n",
      "\n",
      "Main categories: ['Computer Science', 'Economics', 'EE & Systems Science', 'Mathematics', 'Physics', 'Quantitative Biology', 'Quantitative Finance', 'Statistics']\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# arXiv Category Configuration\n",
    "# =============================================================================\n",
    "# Load categories from CSV file (download from GitHub if not present)\n",
    "# Each category is fetched individually with rate limiting (5s delay)\n",
    "\n",
    "ARXIV_CATEGORIES_CSV = 'data/arxiv_v2.csv'\n",
    "ARXIV_CATEGORIES_URL = 'https://raw.githubusercontent.com/Edwinexd/arxiv-rag-agent/refs/heads/master/data/arxiv_v2.csv'\n",
    "\n",
    "def load_arxiv_categories(csv_path: str, csv_url: str) -> tuple[list[str], pd.DataFrame]:\n",
    "    \"\"\"Load arXiv categories from CSV file, downloading if needed.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (list of category codes, full DataFrame with metadata)\n",
    "    \"\"\"\n",
    "    # Download if file doesn't exist (e.g., in Colab)\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Downloading categories from: {csv_url}\")\n",
    "        os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "        urllib.request.urlretrieve(csv_url, csv_path)\n",
    "    \n",
    "    print(f\"Loading categories from: {csv_path}\")\n",
    "    categories_df = pd.read_csv(csv_path)\n",
    "    category_codes = categories_df['code'].tolist()\n",
    "    print(f\"Found {len(category_codes)} categories\")\n",
    "    return category_codes, categories_df\n",
    "\n",
    "# Load categories from CSV\n",
    "ARXIV_CATEGORIES, CATEGORIES_DF = load_arxiv_categories(ARXIV_CATEGORIES_CSV, ARXIV_CATEGORIES_URL)\n",
    "\n",
    "# Optional: Filter to specific subject areas (uncomment to use)\n",
    "# MAIN_CATEGORIES = ['Computer Science', 'Statistics']\n",
    "# CATEGORIES_DF = CATEGORIES_DF[CATEGORIES_DF['main_category'].isin(MAIN_CATEGORIES)]\n",
    "# ARXIV_CATEGORIES = CATEGORIES_DF['code'].tolist()\n",
    "\n",
    "# Rate limiting configuration\n",
    "FETCH_DELAY_SECONDS = 5\n",
    "\n",
    "# Embedding model configuration\n",
    "EMBEDDING_MODEL = 'all-MiniLM-L6-v2'\n",
    "EMBEDDING_DIM = 384\n",
    "\n",
    "# Hopsworks configuration\n",
    "HOPSWORKS_HOST = os.environ.get('HOPSWORKS_HOST', 'c.app.hopsworks.ai')\n",
    "HOPSWORKS_FEATURE_STORE = os.environ.get('HOPSWORKS_FEATURE_STORE', 'kingaedwin_featurestore')\n",
    "FEATURE_GROUP_NAME = 'arxiv_embeddings_with_cats'\n",
    "FEATURE_GROUP_VERSION = 1\n",
    "\n",
    "print(f\"\\nCategories to fetch: {len(ARXIV_CATEGORIES)}\")\n",
    "print(f\"Delay between requests: {FETCH_DELAY_SECONDS}s\")\n",
    "print(f\"Estimated fetch time: ~{(len(ARXIV_CATEGORIES) * FETCH_DELAY_SECONDS) // 60} min {(len(ARXIV_CATEGORIES) * FETCH_DELAY_SECONDS) % 60}s\")\n",
    "print(f\"\\nMain categories: {CATEGORIES_DF['main_category'].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. arXiv RSS Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Clean and normalize text from RSS feed.\"\"\"\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def extract_arxiv_id(link: str) -> float:\n",
    "    \"\"\"Extract arXiv ID from URL and convert to float.\"\"\"\n",
    "    match = re.search(r'abs/([\\d.]+)', link)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_main_category(code: str, categories_df: pd.DataFrame) -> str:\n",
    "    \"\"\"Look up main category for a given arXiv category code.\"\"\"\n",
    "    match = categories_df[categories_df['code'] == code]\n",
    "    if not match.empty:\n",
    "        return match.iloc[0]['main_category']\n",
    "    return 'Unknown'\n",
    "\n",
    "\n",
    "def extract_categories(entry: dict, categories_df: pd.DataFrame) -> tuple[list[str], list[str]]:\n",
    "    \"\"\"Extract main category and sub-categories (codes) from entry.\"\"\"\n",
    "    tags = entry.get('tags', [])\n",
    "    \n",
    "    if not tags:\n",
    "        return ['Unknown'], []\n",
    "    \n",
    "    # Extract all category codes\n",
    "    codes = [tag.get('term', '') for tag in tags if tag.get('term')]\n",
    "    \n",
    "    if codes:\n",
    "        # Look up main category from primary code\n",
    "        main_cat = get_main_category(codes[0], categories_df)\n",
    "        return [main_cat], codes\n",
    "    \n",
    "    return ['Unknown'], []\n",
    "\n",
    "\n",
    "def parse_arxiv_feed(feed_url: str, categories_df: pd.DataFrame) -> list[dict]:\n",
    "    \"\"\"Parse arXiv RSS feed and return list of papers.\"\"\"\n",
    "    feed = feedparser.parse(feed_url)\n",
    "    papers = []\n",
    "    \n",
    "    for entry in feed.entries:\n",
    "        main_cats, codes = extract_categories(entry, categories_df)\n",
    "        \n",
    "        paper = {\n",
    "            'id': extract_arxiv_id(entry.get('link', '')),\n",
    "            'title': clean_text(entry.get('title', '')),\n",
    "            'abstract': clean_text(entry.get('summary', '')),\n",
    "            'categories': main_cats,         # array<string> - main category (e.g., \"Physics\")\n",
    "            'sub_categories': codes,         # array<string> - actual codes (e.g., \"hep-th\")\n",
    "            'link': entry.get('link', ''),\n",
    "            'published': entry.get('published', ''),\n",
    "            'authors': ', '.join([a.get('name', '') for a in entry.get('authors', [])]),\n",
    "        }\n",
    "        papers.append(paper)\n",
    "    \n",
    "    return papers\n",
    "\n",
    "\n",
    "def get_fallback_paper() -> dict:\n",
    "    \"\"\"Return a fallback test paper for days with no publications (e.g., weekends).\"\"\"\n",
    "    return {\n",
    "        'id': 2511.17836,\n",
    "        'title': 'Validating API Design Requirements for Interoperability: A Static Analysis Approach Using OpenAPI',\n",
    "        'abstract': 'This paper presents S.E.O.R.A, a configurable tool that uses static analysis to validate RESTful API designs against 75 identified rules. Through Design Science Research methodology, the authors developed a rule engine to detect structural violations in OpenAPI specifications. The work emphasizes how API quality validation contributes to aligning technical designs with requirements and enterprise architecture by strengthening interoperability and governance between enterprise systems.',\n",
    "        'categories': ['Computer Science'],\n",
    "        'sub_categories': ['cs.SE'],\n",
    "        'link': 'https://arxiv.org/abs/2511.17836',\n",
    "        'published': '2025-11-21',\n",
    "        'authors': 'Edwin Sundberg, Thea Ekmark, Workneh Yilma Ayele',\n",
    "    }\n",
    "\n",
    "\n",
    "def is_weekend() -> bool:\n",
    "    \"\"\"Check if today is Saturday (5) or Sunday (6).\"\"\"\n",
    "    return datetime.utcnow().weekday() >= 5\n",
    "\n",
    "\n",
    "def fetch_all_categories(categories: list[str], categories_df: pd.DataFrame, delay_seconds: int = 5) -> list[dict]:\n",
    "    \"\"\"Fetch papers from each category individually with rate limiting.\n",
    "    \n",
    "    Args:\n",
    "        categories: List of arXiv category codes (e.g., ['cs.AI', 'cs.LG'])\n",
    "        categories_df: DataFrame with category metadata\n",
    "        delay_seconds: Seconds to wait between requests\n",
    "        \n",
    "    Returns:\n",
    "        Combined list of all papers from all categories\n",
    "    \"\"\"\n",
    "    # Skip fetching on weekends - arXiv doesn't publish\n",
    "    if is_weekend():\n",
    "        print(\"Weekend detected - arXiv doesn't publish on Sat/Sun.\")\n",
    "        print(\"Using fallback test paper.\")\n",
    "        return [get_fallback_paper()]\n",
    "    \n",
    "    all_papers = []\n",
    "    \n",
    "    for i, category in enumerate(categories):\n",
    "        feed_url = f\"https://rss.arxiv.org/rss/{category}\"\n",
    "        print(f\"[{i+1}/{len(categories)}] Fetching {category}...\", end=\" \")\n",
    "        \n",
    "        papers = parse_arxiv_feed(feed_url, categories_df)\n",
    "        all_papers.extend(papers)\n",
    "        print(f\"found {len(papers)} papers\")\n",
    "        \n",
    "        # Rate limit: wait before next request (skip delay after last category)\n",
    "        if i < len(categories) - 1:\n",
    "            print(f\"    Waiting {delay_seconds}s...\")\n",
    "            time.sleep(delay_seconds)\n",
    "    \n",
    "    return all_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/155] Fetching cs.AI... found 152 papers\n",
      "    Waiting 5s...\n",
      "[2/155] Fetching cs.AR... found 6 papers\n",
      "    Waiting 5s...\n",
      "[3/155] Fetching cs.CC... found 7 papers\n",
      "    Waiting 5s...\n",
      "[4/155] Fetching cs.CE... found 14 papers\n",
      "    Waiting 5s...\n",
      "[5/155] Fetching cs.CG... found 5 papers\n",
      "    Waiting 5s...\n",
      "[6/155] Fetching cs.CL... found 92 papers\n",
      "    Waiting 5s...\n",
      "[7/155] Fetching cs.CR... found 44 papers\n",
      "    Waiting 5s...\n",
      "[8/155] Fetching cs.CV... found 134 papers\n",
      "    Waiting 5s...\n",
      "[9/155] Fetching cs.CY... found 15 papers\n",
      "    Waiting 5s...\n",
      "[10/155] Fetching cs.DB... found 11 papers\n",
      "    Waiting 5s...\n",
      "[11/155] Fetching cs.DC... found 18 papers\n",
      "    Waiting 5s...\n",
      "[12/155] Fetching cs.DL... found 0 papers\n",
      "    Waiting 5s...\n",
      "[13/155] Fetching cs.DM... found 4 papers\n",
      "    Waiting 5s...\n",
      "[14/155] Fetching cs.DS... found 10 papers\n",
      "    Waiting 5s...\n",
      "[15/155] Fetching cs.ET... found 12 papers\n",
      "    Waiting 5s...\n",
      "[16/155] Fetching cs.FL... found 0 papers\n",
      "    Waiting 5s...\n",
      "[17/155] Fetching cs.GL... found 0 papers\n",
      "    Waiting 5s...\n",
      "[18/155] Fetching cs.GR... found 8 papers\n",
      "    Waiting 5s...\n",
      "[19/155] Fetching cs.GT... found 9 papers\n",
      "    Waiting 5s...\n",
      "[20/155] Fetching cs.HC... found 19 papers\n",
      "    Waiting 5s...\n",
      "[21/155] Fetching cs.IR... found 9 papers\n",
      "    Waiting 5s...\n",
      "[22/155] Fetching cs.IT... found 22 papers\n",
      "    Waiting 5s...\n",
      "[23/155] Fetching cs.LG... found 179 papers\n",
      "    Waiting 5s...\n",
      "[24/155] Fetching cs.LO... found 3 papers\n",
      "    Waiting 5s...\n",
      "[25/155] Fetching cs.MA... found 11 papers\n",
      "    Waiting 5s...\n",
      "[26/155] Fetching cs.MM... found 7 papers\n",
      "    Waiting 5s...\n",
      "[27/155] Fetching cs.MS... found 3 papers\n",
      "    Waiting 5s...\n",
      "[28/155] Fetching cs.NA... found 22 papers\n",
      "    Waiting 5s...\n",
      "[29/155] Fetching cs.NE... found 18 papers\n",
      "    Waiting 5s...\n",
      "[30/155] Fetching cs.NI... found 14 papers\n",
      "    Waiting 5s...\n",
      "[31/155] Fetching cs.OH... found 0 papers\n",
      "    Waiting 5s...\n",
      "[32/155] Fetching cs.OS... found 2 papers\n",
      "    Waiting 5s...\n",
      "[33/155] Fetching cs.PF... found 1 papers\n",
      "    Waiting 5s...\n",
      "[34/155] Fetching cs.PL... found 2 papers\n",
      "    Waiting 5s...\n",
      "[35/155] Fetching cs.RO... found 39 papers\n",
      "    Waiting 5s...\n",
      "[36/155] Fetching cs.SC... found 4 papers\n",
      "    Waiting 5s...\n",
      "[37/155] Fetching cs.SD... found 6 papers\n",
      "    Waiting 5s...\n",
      "[38/155] Fetching cs.SE... found 21 papers\n",
      "    Waiting 5s...\n",
      "[39/155] Fetching cs.SI... found 7 papers\n",
      "    Waiting 5s...\n",
      "[40/155] Fetching cs.SY... found 22 papers\n",
      "    Waiting 5s...\n",
      "[41/155] Fetching econ.EM... found 4 papers\n",
      "    Waiting 5s...\n",
      "[42/155] Fetching econ.GN... found 5 papers\n",
      "    Waiting 5s...\n",
      "[43/155] Fetching econ.TH... found 6 papers\n",
      "    Waiting 5s...\n",
      "[44/155] Fetching eess.AS... found 6 papers\n",
      "    Waiting 5s...\n",
      "[45/155] Fetching eess.IV... found 12 papers\n",
      "    Waiting 5s...\n",
      "[46/155] Fetching eess.SP... found 23 papers\n",
      "    Waiting 5s...\n",
      "[47/155] Fetching eess.SY... found 22 papers\n",
      "    Waiting 5s...\n",
      "[48/155] Fetching math.AC... found 3 papers\n",
      "    Waiting 5s...\n",
      "[49/155] Fetching math.AG... found 28 papers\n",
      "    Waiting 5s...\n",
      "[50/155] Fetching math.AP... found 23 papers\n",
      "    Waiting 5s...\n",
      "[51/155] Fetching math.AT... found 10 papers\n",
      "    Waiting 5s...\n",
      "[52/155] Fetching math.CA... found 10 papers\n",
      "    Waiting 5s...\n",
      "[53/155] Fetching math.CO... found 36 papers\n",
      "    Waiting 5s...\n",
      "[54/155] Fetching math.CT... found 4 papers\n",
      "    Waiting 5s...\n",
      "[55/155] Fetching math.CV... found 5 papers\n",
      "    Waiting 5s...\n",
      "[56/155] Fetching math.DG... found 8 papers\n",
      "    Waiting 5s...\n",
      "[57/155] Fetching math.DS... found 19 papers\n",
      "    Waiting 5s...\n",
      "[58/155] Fetching math.FA... found 17 papers\n",
      "    Waiting 5s...\n",
      "[59/155] Fetching math.GM... found 2 papers\n",
      "    Waiting 5s...\n",
      "[60/155] Fetching math.GN... found 4 papers\n",
      "    Waiting 5s...\n",
      "[61/155] Fetching math.GR... found 10 papers\n",
      "    Waiting 5s...\n",
      "[62/155] Fetching math.GT... found 10 papers\n",
      "    Waiting 5s...\n",
      "[63/155] Fetching math.HO... found 4 papers\n",
      "    Waiting 5s...\n",
      "[64/155] Fetching math.IT... found 22 papers\n",
      "    Waiting 5s...\n",
      "[65/155] Fetching math.KT... found 2 papers\n",
      "    Waiting 5s...\n",
      "[66/155] Fetching math.LO... found 14 papers\n",
      "    Waiting 5s...\n",
      "[67/155] Fetching math.MG... found 2 papers\n",
      "    Waiting 5s...\n",
      "[68/155] Fetching math.MP... found 41 papers\n",
      "    Waiting 5s...\n",
      "[69/155] Fetching math.NA... found 22 papers\n",
      "    Waiting 5s...\n",
      "[70/155] Fetching math.NT... found 27 papers\n",
      "    Waiting 5s...\n",
      "[71/155] Fetching math.OA... found 4 papers\n",
      "    Waiting 5s...\n",
      "[72/155] Fetching math.OC... found 30 papers\n",
      "    Waiting 5s...\n",
      "[73/155] Fetching math.PR... found 22 papers\n",
      "    Waiting 5s...\n",
      "[74/155] Fetching math.QA... found 9 papers\n",
      "    Waiting 5s...\n",
      "[75/155] Fetching math.RA... found 8 papers\n",
      "    Waiting 5s...\n",
      "[76/155] Fetching math.RT... found 20 papers\n",
      "    Waiting 5s...\n",
      "[77/155] Fetching math.SG... found 6 papers\n",
      "    Waiting 5s...\n",
      "[78/155] Fetching math.SP... found 3 papers\n",
      "    Waiting 5s...\n",
      "[79/155] Fetching math.ST... found 17 papers\n",
      "    Waiting 5s...\n",
      "[80/155] Fetching astro-ph.CO... found 22 papers\n",
      "    Waiting 5s...\n",
      "[81/155] Fetching astro-ph.EP... found 11 papers\n",
      "    Waiting 5s...\n",
      "[82/155] Fetching astro-ph.GA... found 21 papers\n",
      "    Waiting 5s...\n",
      "[83/155] Fetching astro-ph.HE... found 22 papers\n",
      "    Waiting 5s...\n",
      "[84/155] Fetching astro-ph.IM... found 12 papers\n",
      "    Waiting 5s...\n",
      "[85/155] Fetching astro-ph.SR... found 15 papers\n",
      "    Waiting 5s...\n",
      "[86/155] Fetching cond-mat.dis-nn... found 7 papers\n",
      "    Waiting 5s...\n",
      "[87/155] Fetching cond-mat.mes-hall... found 29 papers\n",
      "    Waiting 5s...\n",
      "[88/155] Fetching cond-mat.mtrl-sci... found 35 papers\n",
      "    Waiting 5s...\n",
      "[89/155] Fetching cond-mat.other... found 8 papers\n",
      "    Waiting 5s...\n",
      "[90/155] Fetching cond-mat.quant-gas... found 5 papers\n",
      "    Waiting 5s...\n",
      "[91/155] Fetching cond-mat.soft... found 16 papers\n",
      "    Waiting 5s...\n",
      "[92/155] Fetching cond-mat.stat-mech... found 24 papers\n",
      "    Waiting 5s...\n",
      "[93/155] Fetching cond-mat.str-el... found 18 papers\n",
      "    Waiting 5s...\n",
      "[94/155] Fetching cond-mat.supr-con... found 5 papers\n",
      "    Waiting 5s...\n",
      "[95/155] Fetching gr-qc... found 41 papers\n",
      "    Waiting 5s...\n",
      "[96/155] Fetching hep-ex... found 18 papers\n",
      "    Waiting 5s...\n",
      "[97/155] Fetching hep-lat... found 3 papers\n",
      "    Waiting 5s...\n",
      "[98/155] Fetching hep-ph... found 34 papers\n",
      "    Waiting 5s...\n",
      "[99/155] Fetching hep-th... found 46 papers\n",
      "    Waiting 5s...\n",
      "[100/155] Fetching math-ph... found 41 papers\n",
      "    Waiting 5s...\n",
      "[101/155] Fetching nlin.AO... found 4 papers\n",
      "    Waiting 5s...\n",
      "[102/155] Fetching nlin.CD... found 6 papers\n",
      "    Waiting 5s...\n",
      "[103/155] Fetching nlin.CG... found 2 papers\n",
      "    Waiting 5s...\n",
      "[104/155] Fetching nlin.PS... found 2 papers\n",
      "    Waiting 5s...\n",
      "[105/155] Fetching nlin.SI... found 4 papers\n",
      "    Waiting 5s...\n",
      "[106/155] Fetching nucl-ex... found 4 papers\n",
      "    Waiting 5s...\n",
      "[107/155] Fetching nucl-th... found 7 papers\n",
      "    Waiting 5s...\n",
      "[108/155] Fetching physics.acc-ph... found 1 papers\n",
      "    Waiting 5s...\n",
      "[109/155] Fetching physics.ao-ph... found 6 papers\n",
      "    Waiting 5s...\n",
      "[110/155] Fetching physics.app-ph... found 22 papers\n",
      "    Waiting 5s...\n",
      "[111/155] Fetching physics.atm-clus... found 1 papers\n",
      "    Waiting 5s...\n",
      "[112/155] Fetching physics.atom-ph... found 3 papers\n",
      "    Waiting 5s...\n",
      "[113/155] Fetching physics.bio-ph... found 7 papers\n",
      "    Waiting 5s...\n",
      "[114/155] Fetching physics.chem-ph... found 13 papers\n",
      "    Waiting 5s...\n",
      "[115/155] Fetching physics.class-ph... found 4 papers\n",
      "    Waiting 5s...\n",
      "[116/155] Fetching physics.comp-ph... found 15 papers\n",
      "    Waiting 5s...\n",
      "[117/155] Fetching physics.data-an... found 2 papers\n",
      "    Waiting 5s...\n",
      "[118/155] Fetching physics.ed-ph... found 0 papers\n",
      "    Waiting 5s...\n",
      "[119/155] Fetching physics.flu-dyn... found 17 papers\n",
      "    Waiting 5s...\n",
      "[120/155] Fetching physics.gen-ph... found 0 papers\n",
      "    Waiting 5s...\n",
      "[121/155] Fetching physics.geo-ph... found 6 papers\n",
      "    Waiting 5s...\n",
      "[122/155] Fetching physics.hist-ph... found 3 papers\n",
      "    Waiting 5s...\n",
      "[123/155] Fetching physics.ins-det... found 6 papers\n",
      "    Waiting 5s...\n",
      "[124/155] Fetching physics.med-ph... found 8 papers\n",
      "    Waiting 5s...\n",
      "[125/155] Fetching physics.optics... found 36 papers\n",
      "    Waiting 5s...\n",
      "[126/155] Fetching physics.plasm-ph... found 15 papers\n",
      "    Waiting 5s...\n",
      "[127/155] Fetching physics.pop-ph... found 1 papers\n",
      "    Waiting 5s...\n",
      "[128/155] Fetching physics.soc-ph... found 7 papers\n",
      "    Waiting 5s...\n",
      "[129/155] Fetching physics.space-ph... found 6 papers\n",
      "    Waiting 5s...\n",
      "[130/155] Fetching quant-ph... found 87 papers\n",
      "    Waiting 5s...\n",
      "[131/155] Fetching q-bio.BM... found 3 papers\n",
      "    Waiting 5s...\n",
      "[132/155] Fetching q-bio.CB... found 1 papers\n",
      "    Waiting 5s...\n",
      "[133/155] Fetching q-bio.GN... found 1 papers\n",
      "    Waiting 5s...\n",
      "[134/155] Fetching q-bio.MN... found 2 papers\n",
      "    Waiting 5s...\n",
      "[135/155] Fetching q-bio.NC... found 4 papers\n",
      "    Waiting 5s...\n",
      "[136/155] Fetching q-bio.OT... found 1 papers\n",
      "    Waiting 5s...\n",
      "[137/155] Fetching q-bio.PE... found 7 papers\n",
      "    Waiting 5s...\n",
      "[138/155] Fetching q-bio.QM... found 15 papers\n",
      "    Waiting 5s...\n",
      "[139/155] Fetching q-bio.SC... found 0 papers\n",
      "    Waiting 5s...\n",
      "[140/155] Fetching q-bio.TO... found 0 papers\n",
      "    Waiting 5s...\n",
      "[141/155] Fetching q-fin.CP... found 3 papers\n",
      "    Waiting 5s...\n",
      "[142/155] Fetching q-fin.EC... found 5 papers\n",
      "    Waiting 5s...\n",
      "[143/155] Fetching q-fin.GN... found 2 papers\n",
      "    Waiting 5s...\n",
      "[144/155] Fetching q-fin.MF... found 2 papers\n",
      "    Waiting 5s...\n",
      "[145/155] Fetching q-fin.PM... found 3 papers\n",
      "    Waiting 5s...\n",
      "[146/155] Fetching q-fin.PR... found 0 papers\n",
      "    Waiting 5s...\n",
      "[147/155] Fetching q-fin.RM... found 4 papers\n",
      "    Waiting 5s...\n",
      "[148/155] Fetching q-fin.ST... found 3 papers\n",
      "    Waiting 5s...\n",
      "[149/155] Fetching q-fin.TR... found 2 papers\n",
      "    Waiting 5s...\n",
      "[150/155] Fetching stat.AP... found 11 papers\n",
      "    Waiting 5s...\n",
      "[151/155] Fetching stat.CO... found 6 papers\n",
      "    Waiting 5s...\n",
      "[152/155] Fetching stat.ME... found 30 papers\n",
      "    Waiting 5s...\n",
      "[153/155] Fetching stat.ML... found 27 papers\n",
      "    Waiting 5s...\n",
      "[154/155] Fetching stat.OT... found 0 papers\n",
      "    Waiting 5s...\n",
      "[155/155] Fetching stat.TH... found 17 papers\n",
      "\n",
      "Total papers fetched: 2349\n",
      "Unique papers after deduplication: 1307\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5cc717bf-1bac-44e2-8160-d966699d65f4\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "      <th>sub_categories</th>\n",
       "      <th>link</th>\n",
       "      <th>published</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2601.00003</td>\n",
       "      <td>Reasoning in Action: MCTS-Driven Knowledge Ret...</td>\n",
       "      <td>arXiv:2601.00003v1 Announce Type: new Abstract...</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>[cs.AI, cs.CL]</td>\n",
       "      <td>https://arxiv.org/abs/2601.00003</td>\n",
       "      <td>Mon, 05 Jan 2026 00:00:00 -0500</td>\n",
       "      <td>Shuqi Liu, Bowei He, Chen Ma, Linqi Song</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2601.00004</td>\n",
       "      <td>Finetuning Large Language Models for Automated...</td>\n",
       "      <td>arXiv:2601.00004v1 Announce Type: new Abstract...</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>[cs.AI, cs.CL, cs.LG]</td>\n",
       "      <td>https://arxiv.org/abs/2601.00004</td>\n",
       "      <td>Mon, 05 Jan 2026 00:00:00 -0500</td>\n",
       "      <td>Isaac Iyinoluwa Olufadewa, Miracle Ayomikun Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2601.00021</td>\n",
       "      <td>Toward a Physical Theory of Intelligence</td>\n",
       "      <td>arXiv:2601.00021v1 Announce Type: new Abstract...</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>[cs.AI]</td>\n",
       "      <td>https://arxiv.org/abs/2601.00021</td>\n",
       "      <td>Mon, 05 Jan 2026 00:00:00 -0500</td>\n",
       "      <td>Peter David Fagan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2601.00023</td>\n",
       "      <td>A multi-algorithm approach for operational hum...</td>\n",
       "      <td>arXiv:2601.00023v1 Announce Type: new Abstract...</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>[cs.AI, cs.LG]</td>\n",
       "      <td>https://arxiv.org/abs/2601.00023</td>\n",
       "      <td>Mon, 05 Jan 2026 00:00:00 -0500</td>\n",
       "      <td>Luis M. Moreno-Saavedra, Silvia Jimenez-Fernan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2601.00024</td>\n",
       "      <td>Quantitative Rule-Based Strategy modeling in C...</td>\n",
       "      <td>arXiv:2601.00024v1 Announce Type: new Abstract...</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>[cs.AI, cs.GT]</td>\n",
       "      <td>https://arxiv.org/abs/2601.00024</td>\n",
       "      <td>Mon, 05 Jan 2026 00:00:00 -0500</td>\n",
       "      <td>Purushottam Saha, Avirup Chakraborty, Sourish ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cc717bf-1bac-44e2-8160-d966699d65f4')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-5cc717bf-1bac-44e2-8160-d966699d65f4 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-5cc717bf-1bac-44e2-8160-d966699d65f4');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "           id                                              title  \\\n",
       "0  2601.00003  Reasoning in Action: MCTS-Driven Knowledge Ret...   \n",
       "1  2601.00004  Finetuning Large Language Models for Automated...   \n",
       "2  2601.00021           Toward a Physical Theory of Intelligence   \n",
       "3  2601.00023  A multi-algorithm approach for operational hum...   \n",
       "4  2601.00024  Quantitative Rule-Based Strategy modeling in C...   \n",
       "\n",
       "                                            abstract          categories  \\\n",
       "0  arXiv:2601.00003v1 Announce Type: new Abstract...  [Computer Science]   \n",
       "1  arXiv:2601.00004v1 Announce Type: new Abstract...  [Computer Science]   \n",
       "2  arXiv:2601.00021v1 Announce Type: new Abstract...  [Computer Science]   \n",
       "3  arXiv:2601.00023v1 Announce Type: new Abstract...  [Computer Science]   \n",
       "4  arXiv:2601.00024v1 Announce Type: new Abstract...  [Computer Science]   \n",
       "\n",
       "          sub_categories                              link  \\\n",
       "0         [cs.AI, cs.CL]  https://arxiv.org/abs/2601.00003   \n",
       "1  [cs.AI, cs.CL, cs.LG]  https://arxiv.org/abs/2601.00004   \n",
       "2                [cs.AI]  https://arxiv.org/abs/2601.00021   \n",
       "3         [cs.AI, cs.LG]  https://arxiv.org/abs/2601.00023   \n",
       "4         [cs.AI, cs.GT]  https://arxiv.org/abs/2601.00024   \n",
       "\n",
       "                         published  \\\n",
       "0  Mon, 05 Jan 2026 00:00:00 -0500   \n",
       "1  Mon, 05 Jan 2026 00:00:00 -0500   \n",
       "2  Mon, 05 Jan 2026 00:00:00 -0500   \n",
       "3  Mon, 05 Jan 2026 00:00:00 -0500   \n",
       "4  Mon, 05 Jan 2026 00:00:00 -0500   \n",
       "\n",
       "                                             authors  \n",
       "0           Shuqi Liu, Bowei He, Chen Ma, Linqi Song  \n",
       "1  Isaac Iyinoluwa Olufadewa, Miracle Ayomikun Ad...  \n",
       "2                                  Peter David Fagan  \n",
       "3  Luis M. Moreno-Saavedra, Silvia Jimenez-Fernan...  \n",
       "4  Purushottam Saha, Avirup Chakraborty, Sourish ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch papers from each category with rate limiting\n",
    "papers = fetch_all_categories(ARXIV_CATEGORIES, CATEGORIES_DF, FETCH_DELAY_SECONDS)\n",
    "papers_df = pd.DataFrame(papers)\n",
    "\n",
    "# Remove duplicates by ID (papers can appear in multiple categories)\n",
    "papers_df = papers_df.drop_duplicates(subset=['id'], keep='first')\n",
    "print(f\"\\nTotal papers fetched: {len(papers)}\")\n",
    "print(f\"Unique papers after deduplication: {len(papers_df)}\")\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1dc6e41aa3d4e86b686ddf2bd58156d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e0264490754d60b7f03912712a07df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe816f33505417d886cb8f23503a91e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b04cdcd6bf4c4e985ea64e319594a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1849bdf78510477e9f8b15501e62f979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3326d4cd604cdb8674d6273411aa59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b3d8ca3cba4b89a2948d8f184c193a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c73425e76044198974e1339badb2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e09801de5543069d4bdbe808061dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5606acfee424a258823dca534f89bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6017b9dd84364236a2241e1c20d253fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Load the embedding model\n",
    "print(f\"Loading embedding model: {EMBEDDING_MODEL}\")\n",
    "model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "print(f\"Model loaded. Embedding dimension: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(df: pd.DataFrame, model: SentenceTransformer) -> pd.DataFrame:\n",
    "    \"\"\"Generate embeddings for paper titles and abstracts.\"\"\"\n",
    "    # Combine title and abstract for richer embedding\n",
    "    texts = (df['title'] + ' ' + df['abstract']).tolist()\n",
    "    \n",
    "    print(f\"Generating embeddings for {len(texts)} papers...\")\n",
    "    embeddings = model.encode(texts, show_progress_bar=True, batch_size=32)\n",
    "    \n",
    "    # Add embeddings as list of float32 (array<float> for Hopsworks)\n",
    "    df = df.copy()\n",
    "    df['embedding'] = [emb.astype(np.float32).tolist() for emb in embeddings]\n",
    "    \n",
    "    print(f\"Embeddings generated. Shape: {embeddings.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 1307 papers...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2179df80c1ba4a8eb9e39b28f3a7ab8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated. Shape: (1307, 384)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-98da2b1b-3105-4ffd-85cb-3920666b8e2b\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "      <th>sub_categories</th>\n",
       "      <th>link</th>\n",
       "      <th>published</th>\n",
       "      <th>authors</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2601.00003</td>\n",
       "      <td>Reasoning in Action: MCTS-Driven Knowledge Ret...</td>\n",
       "      <td>arXiv:2601.00003v1 Announce Type: new Abstract...</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>[cs.AI, cs.CL]</td>\n",
       "      <td>https://arxiv.org/abs/2601.00003</td>\n",
       "      <td>Mon, 05 Jan 2026 00:00:00 -0500</td>\n",
       "      <td>Shuqi Liu, Bowei He, Chen Ma, Linqi Song</td>\n",
       "      <td>[-0.04069393500685692, -0.08733277767896652, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2601.00004</td>\n",
       "      <td>Finetuning Large Language Models for Automated...</td>\n",
       "      <td>arXiv:2601.00004v1 Announce Type: new Abstract...</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>[cs.AI, cs.CL, cs.LG]</td>\n",
       "      <td>https://arxiv.org/abs/2601.00004</td>\n",
       "      <td>Mon, 05 Jan 2026 00:00:00 -0500</td>\n",
       "      <td>Isaac Iyinoluwa Olufadewa, Miracle Ayomikun Ad...</td>\n",
       "      <td>[0.007354579865932465, 0.01675439067184925, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2601.00021</td>\n",
       "      <td>Toward a Physical Theory of Intelligence</td>\n",
       "      <td>arXiv:2601.00021v1 Announce Type: new Abstract...</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>[cs.AI]</td>\n",
       "      <td>https://arxiv.org/abs/2601.00021</td>\n",
       "      <td>Mon, 05 Jan 2026 00:00:00 -0500</td>\n",
       "      <td>Peter David Fagan</td>\n",
       "      <td>[-0.04428629204630852, -0.0290644783526659, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2601.00023</td>\n",
       "      <td>A multi-algorithm approach for operational hum...</td>\n",
       "      <td>arXiv:2601.00023v1 Announce Type: new Abstract...</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>[cs.AI, cs.LG]</td>\n",
       "      <td>https://arxiv.org/abs/2601.00023</td>\n",
       "      <td>Mon, 05 Jan 2026 00:00:00 -0500</td>\n",
       "      <td>Luis M. Moreno-Saavedra, Silvia Jimenez-Fernan...</td>\n",
       "      <td>[-0.007301397155970335, 0.001086684176698327, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2601.00024</td>\n",
       "      <td>Quantitative Rule-Based Strategy modeling in C...</td>\n",
       "      <td>arXiv:2601.00024v1 Announce Type: new Abstract...</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>[cs.AI, cs.GT]</td>\n",
       "      <td>https://arxiv.org/abs/2601.00024</td>\n",
       "      <td>Mon, 05 Jan 2026 00:00:00 -0500</td>\n",
       "      <td>Purushottam Saha, Avirup Chakraborty, Sourish ...</td>\n",
       "      <td>[0.034368764609098434, 0.008278274908661842, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98da2b1b-3105-4ffd-85cb-3920666b8e2b')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-98da2b1b-3105-4ffd-85cb-3920666b8e2b button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-98da2b1b-3105-4ffd-85cb-3920666b8e2b');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "           id                                              title  \\\n",
       "0  2601.00003  Reasoning in Action: MCTS-Driven Knowledge Ret...   \n",
       "1  2601.00004  Finetuning Large Language Models for Automated...   \n",
       "2  2601.00021           Toward a Physical Theory of Intelligence   \n",
       "3  2601.00023  A multi-algorithm approach for operational hum...   \n",
       "4  2601.00024  Quantitative Rule-Based Strategy modeling in C...   \n",
       "\n",
       "                                            abstract          categories  \\\n",
       "0  arXiv:2601.00003v1 Announce Type: new Abstract...  [Computer Science]   \n",
       "1  arXiv:2601.00004v1 Announce Type: new Abstract...  [Computer Science]   \n",
       "2  arXiv:2601.00021v1 Announce Type: new Abstract...  [Computer Science]   \n",
       "3  arXiv:2601.00023v1 Announce Type: new Abstract...  [Computer Science]   \n",
       "4  arXiv:2601.00024v1 Announce Type: new Abstract...  [Computer Science]   \n",
       "\n",
       "          sub_categories                              link  \\\n",
       "0         [cs.AI, cs.CL]  https://arxiv.org/abs/2601.00003   \n",
       "1  [cs.AI, cs.CL, cs.LG]  https://arxiv.org/abs/2601.00004   \n",
       "2                [cs.AI]  https://arxiv.org/abs/2601.00021   \n",
       "3         [cs.AI, cs.LG]  https://arxiv.org/abs/2601.00023   \n",
       "4         [cs.AI, cs.GT]  https://arxiv.org/abs/2601.00024   \n",
       "\n",
       "                         published  \\\n",
       "0  Mon, 05 Jan 2026 00:00:00 -0500   \n",
       "1  Mon, 05 Jan 2026 00:00:00 -0500   \n",
       "2  Mon, 05 Jan 2026 00:00:00 -0500   \n",
       "3  Mon, 05 Jan 2026 00:00:00 -0500   \n",
       "4  Mon, 05 Jan 2026 00:00:00 -0500   \n",
       "\n",
       "                                             authors  \\\n",
       "0           Shuqi Liu, Bowei He, Chen Ma, Linqi Song   \n",
       "1  Isaac Iyinoluwa Olufadewa, Miracle Ayomikun Ad...   \n",
       "2                                  Peter David Fagan   \n",
       "3  Luis M. Moreno-Saavedra, Silvia Jimenez-Fernan...   \n",
       "4  Purushottam Saha, Avirup Chakraborty, Sourish ...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.04069393500685692, -0.08733277767896652, 0...  \n",
       "1  [0.007354579865932465, 0.01675439067184925, 0....  \n",
       "2  [-0.04428629204630852, -0.0290644783526659, 0....  \n",
       "3  [-0.007301397155970335, 0.001086684176698327, ...  \n",
       "4  [0.034368764609098434, 0.008278274908661842, -...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate embeddings\n",
    "papers_with_embeddings = generate_embeddings(papers_df, model)\n",
    "papers_with_embeddings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Connect to Hopsworks and Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1286343\n"
     ]
    }
   ],
   "source": [
    "# Connect to Hopsworks\n",
    "# API key should be set via HOPSWORKS_API_KEY environment variable\n",
    "project = hopsworks.login(host=HOPSWORKS_HOST)\n",
    "fs = project.get_feature_store(name=HOPSWORKS_FEATURE_STORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_hopsworks(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Prepare dataframe for Hopsworks ingestion.\n",
    "    \n",
    "    Schema (from feature group):\n",
    "    - id: double (primary key)\n",
    "    - embedding: array<float> (float32)\n",
    "    - categories: array<string>\n",
    "    - sub_categories: array<string>\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Select only the columns needed for the feature group\n",
    "    result = df[['id', 'embedding', 'categories', 'sub_categories']].copy()\n",
    "    \n",
    "    # id must be double (float64)\n",
    "    result['id'] = result['id'].astype(float)\n",
    "    \n",
    "    # Check for valid embeddings (must be list/array with no NaN/Inf)\n",
    "    def is_valid_embedding(emb):\n",
    "        if not isinstance(emb, (list, np.ndarray)):\n",
    "            return False\n",
    "        arr = np.array(emb)\n",
    "        if np.any(np.isnan(arr)) or np.any(np.isinf(arr)):\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    # Filter to only valid rows\n",
    "    valid_mask = result['embedding'].apply(is_valid_embedding)\n",
    "    invalid_count = (~valid_mask).sum()\n",
    "    if invalid_count > 0:\n",
    "        print(f\"Dropping {invalid_count} rows with invalid embeddings\")\n",
    "    result = result[valid_mask].copy()\n",
    "    \n",
    "    # Convert embeddings to numpy float32 arrays (like backfill does with model.encode())\n",
    "    def to_numpy_float32(emb):\n",
    "        arr = np.array(emb, dtype=np.float32)\n",
    "        arr = np.nan_to_num(arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return arr\n",
    "    \n",
    "    result['embedding'] = result['embedding'].apply(to_numpy_float32)\n",
    "    \n",
    "    print(f\"Prepared {len(result)} valid rows\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 1307 valid rows\n",
      "Prepared DataFrame shape: (1307, 4)\n",
      "Columns: ['id', 'embedding', 'categories', 'sub_categories']\n",
      "\n",
      "=== NaN Check ===\n",
      "id: 0 NaN values\n",
      "id (float nan check): 0 NaN values\n",
      "embedding: 0 NaN values inside arrays\n",
      "embedding: 0 null/None embeddings\n",
      "categories: 0 non-list values\n",
      "categories: 0 rows with None/NaN inside\n",
      "sub_categories: 0 non-list values\n",
      "sub_categories: 0 rows with None/NaN inside\n",
      "\n",
      "=== Sample Data ===\n",
      "           id                                          embedding  \\\n",
      "0  2601.00003  [-0.040693935, -0.08733278, 0.05652741, 0.0738...   \n",
      "1  2601.00004  [0.00735458, 0.01675439, 0.051043645, 0.049861...   \n",
      "2  2601.00021  [-0.044286292, -0.029064478, 0.0013241284, 0.0...   \n",
      "3  2601.00023  [-0.007301397, 0.0010866842, -0.026225733, -0....   \n",
      "4  2601.00024  [0.034368765, 0.008278275, -0.006559789, -0.08...   \n",
      "\n",
      "           categories         sub_categories  \n",
      "0  [Computer Science]         [cs.AI, cs.CL]  \n",
      "1  [Computer Science]  [cs.AI, cs.CL, cs.LG]  \n",
      "2  [Computer Science]                [cs.AI]  \n",
      "3  [Computer Science]         [cs.AI, cs.LG]  \n",
      "4  [Computer Science]         [cs.AI, cs.GT]  \n"
     ]
    }
   ],
   "source": [
    "# Prepare data for Hopsworks\n",
    "hopsworks_df = prepare_for_hopsworks(papers_with_embeddings)\n",
    "print(f\"Prepared DataFrame shape: {hopsworks_df.shape}\")\n",
    "print(f\"Columns: {hopsworks_df.columns.tolist()}\")\n",
    "\n",
    "# Debug: Check for NaN values in ALL columns\n",
    "print(\"\\n=== NaN Check ===\")\n",
    "\n",
    "# Check id\n",
    "nan_ids = hopsworks_df['id'].isna().sum()\n",
    "print(f\"id: {nan_ids} NaN values\")\n",
    "if nan_ids == 0:\n",
    "    # Also check for actual nan float values\n",
    "    nan_id_floats = sum(1 for x in hopsworks_df['id'] if x != x)\n",
    "    print(f\"id (float nan check): {nan_id_floats} NaN values\")\n",
    "\n",
    "# Check embeddings\n",
    "def count_nan_in_array(arr):\n",
    "    if arr is None:\n",
    "        return 0\n",
    "    return np.sum(np.isnan(arr))\n",
    "\n",
    "embedding_nans = hopsworks_df['embedding'].apply(count_nan_in_array).sum()\n",
    "print(f\"embedding: {embedding_nans} NaN values inside arrays\")\n",
    "\n",
    "# Check if any embedding is entirely NaN/None\n",
    "null_embeddings = hopsworks_df['embedding'].apply(lambda x: x is None).sum()\n",
    "print(f\"embedding: {null_embeddings} null/None embeddings\")\n",
    "\n",
    "# Check categories and sub_categories for any issues\n",
    "for col in ['categories', 'sub_categories']:\n",
    "    # Check if any are not lists\n",
    "    not_list = sum(1 for x in hopsworks_df[col] if not isinstance(x, list))\n",
    "    print(f\"{col}: {not_list} non-list values\")\n",
    "    \n",
    "    # Check if any contain None or NaN\n",
    "    def has_bad_values(lst):\n",
    "        if not isinstance(lst, list):\n",
    "            return True\n",
    "        for item in lst:\n",
    "            if item is None:\n",
    "                return True\n",
    "            if isinstance(item, float) and (item != item):  # NaN check\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    bad_values = sum(1 for x in hopsworks_df[col] if has_bad_values(x))\n",
    "    print(f\"{col}: {bad_values} rows with None/NaN inside\")\n",
    "\n",
    "print(\"\\n=== Sample Data ===\")\n",
    "print(hopsworks_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting 1307 papers into feature group...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uploading Dataframe: 100.00% |██████████| Rows 1307/1307 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: arxiv_embeddings_with_cats_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286343/jobs/named/arxiv_embeddings_with_cats_1_offline_fg_materialization/executions\n",
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# Get the existing feature group\n",
    "arxiv_fg = fs.get_feature_group(\n",
    "    name=FEATURE_GROUP_NAME,\n",
    "    version=FEATURE_GROUP_VERSION,\n",
    ")\n",
    "\n",
    "# Insert the data\n",
    "print(f\"Inserting {len(hopsworks_df)} papers into feature group...\")\n",
    "arxiv_fg.insert(hopsworks_df)\n",
    "print(\"Data inserted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying inserted data...\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.61s) \n",
      "Sample of stored data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-dd5cee80-bffe-4057-9eaf-0328adfbd306\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>categories</th>\n",
       "      <th>sub_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704.0132</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[cond-mat.mes-hall]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.0123</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[nlin.CD, cond-mat.other, physics.optics]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>704.0114</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[cond-mat.str-el]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>704.0088</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[physics.optics]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704.0033</td>\n",
       "      <td>[Physics]</td>\n",
       "      <td>[physics.optics, physics.comp-ph]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd5cee80-bffe-4057-9eaf-0328adfbd306')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-dd5cee80-bffe-4057-9eaf-0328adfbd306 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-dd5cee80-bffe-4057-9eaf-0328adfbd306');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         id categories                             sub_categories\n",
       "0  704.0132  [Physics]                        [cond-mat.mes-hall]\n",
       "1  704.0123  [Physics]  [nlin.CD, cond-mat.other, physics.optics]\n",
       "2  704.0114  [Physics]                          [cond-mat.str-el]\n",
       "3  704.0088  [Physics]                           [physics.optics]\n",
       "4  704.0033  [Physics]          [physics.optics, physics.comp-ph]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read back some data to verify\n",
    "print(\"Verifying inserted data...\")\n",
    "sample = arxiv_fg.read().head(5)\n",
    "print(f\"Sample of stored data:\")\n",
    "sample[['id', 'categories', 'sub_categories']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pipeline Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Daily Pipeline Summary\n",
      "==================================================\n",
      "Papers fetched: 1\n",
      "Embeddings generated: 1\n",
      "Records inserted to Hopsworks: 1\n",
      "Categories requested: cs.AI, cs.AR, cs.CC, cs.CE, cs.CG, cs.CL, cs.CR, cs.CV, cs.CY, cs.DB, cs.DC, cs.DL, cs.DM, cs.DS, cs.ET, cs.FL, cs.GL, cs.GR, cs.GT, cs.HC, cs.IR, cs.IT, cs.LG, cs.LO, cs.MA, cs.MM, cs.MS, cs.NA, cs.NE, cs.NI, cs.OH, cs.OS, cs.PF, cs.PL, cs.RO, cs.SC, cs.SD, cs.SE, cs.SI, cs.SY, econ.EM, econ.GN, econ.TH, eess.AS, eess.IV, eess.SP, eess.SY, math.AC, math.AG, math.AP, math.AT, math.CA, math.CO, math.CT, math.CV, math.DG, math.DS, math.FA, math.GM, math.GN, math.GR, math.GT, math.HO, math.IT, math.KT, math.LO, math.MG, math.MP, math.NA, math.NT, math.OA, math.OC, math.PR, math.QA, math.RA, math.RT, math.SG, math.SP, math.ST, astro-ph.CO, astro-ph.EP, astro-ph.GA, astro-ph.HE, astro-ph.IM, astro-ph.SR, cond-mat.dis-nn, cond-mat.mes-hall, cond-mat.mtrl-sci, cond-mat.other, cond-mat.quant-gas, cond-mat.soft, cond-mat.stat-mech, cond-mat.str-el, cond-mat.supr-con, gr-qc, hep-ex, hep-lat, hep-ph, hep-th, math-ph, nlin.AO, nlin.CD, nlin.CG, nlin.PS, nlin.SI, nucl-ex, nucl-th, physics.acc-ph, physics.ao-ph, physics.app-ph, physics.atm-clus, physics.atom-ph, physics.bio-ph, physics.chem-ph, physics.class-ph, physics.comp-ph, physics.data-an, physics.ed-ph, physics.flu-dyn, physics.gen-ph, physics.geo-ph, physics.hist-ph, physics.ins-det, physics.med-ph, physics.optics, physics.plasm-ph, physics.pop-ph, physics.soc-ph, physics.space-ph, quant-ph, q-bio.BM, q-bio.CB, q-bio.GN, q-bio.MN, q-bio.NC, q-bio.OT, q-bio.PE, q-bio.QM, q-bio.SC, q-bio.TO, q-fin.CP, q-fin.EC, q-fin.GN, q-fin.MF, q-fin.PM, q-fin.PR, q-fin.RM, q-fin.ST, q-fin.TR, stat.AP, stat.CO, stat.ME, stat.ML, stat.OT, stat.TH\n",
      "Timestamp: 2026-01-03T18:01:32.406611\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"Daily Pipeline Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Papers fetched: {len(papers_df)}\")\n",
    "print(f\"Embeddings generated: {len(papers_with_embeddings)}\")\n",
    "print(f\"Records inserted to Hopsworks: {len(hopsworks_df)}\")\n",
    "print(f\"Categories requested: {', '.join(ARXIV_CATEGORIES)}\")\n",
    "print(f\"Timestamp: {datetime.utcnow().isoformat()}\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
